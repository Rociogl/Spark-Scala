{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto  Final -  Parte 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Parte 2.  Spark SQL**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 1. [Preparación de la plataforma](#1)\n",
    "- 2. [Carga,preparación y análisis mensual de los datos](#2)\n",
    "    - 2.1 [Datos agua](#2.1)\n",
    "    - 2.2 [Datos electricidad](#2.2)\n",
    "    - 2.3 [Datos ficticios ](#2.3)\n",
    "- 3. [Unión de los datasets y análisis](#3)  \n",
    "    - 3.1 [Consumo agua en función de los Edificios](#3.1)\n",
    "    - 3.2 [Consumo elecricidad en función de los Edificios](#3.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta segunda parte se va a llevar a cabo un análisis de los consumos mensuales tanto de agua como de electricidad en función de los meses y por otro lado su relación con respecto a aforos máximos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "### * 1. Preparación de la plataforma. *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "System.setSecurityManager(null)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spark = org.apache.spark.sql.SparkSession@1b004aa2\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ul>\n",
       "<li><a href=\"Some(http://master:4041)\" target=\"new_tab\">Spark UI: local-1580501064108</a></li>\n",
       "</ul>"
      ],
      "text/plain": [
       "Spark local-1580501064108: Some(http://master:4041)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val spark = SparkSession.builder.enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spark.implicits._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.types._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.functions._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a>\n",
    "### * 2. Carga,preparación y análisis de los datos. *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2.1\"></a>\n",
    "### * 2.1 Datos agua. *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "d_agua = [_c0: string, _c1: double ... 5 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[_c0: string, _c1: double ... 5 more fields]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val d_agua= spark.read.format(\"csv\").\n",
    "option(\"delimiter\", \";\").\n",
    "option(\"header\", false). // los datos no incorporan cabecera\n",
    "option(\"inferSchema\", true).\n",
    "load(\"hdfs:///eoi/Proyecto-Final/2013agua.csv\").cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- _c1: double (nullable = true)\n",
      " |-- _c2: integer (nullable = true)\n",
      " |-- _c3: integer (nullable = true)\n",
      " |-- _c4: integer (nullable = true)\n",
      " |-- _c5: integer (nullable = true)\n",
      " |-- _c6: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "d_agua.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "d_agua_cabe = [Edificio: string, Consumo: double ... 5 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[Edificio: string, Consumo: double ... 5 more fields]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val d_agua_cabe = d_agua.withColumnRenamed(\"_c0\", \"Edificio\").withColumnRenamed(\"_c1\", \"Consumo\").withColumnRenamed(\"_c2\", \"Año\").withColumnRenamed(\"_c3\", \"Mes\").withColumnRenamed(\"_c4\", \"Día\").withColumnRenamed(\"_c5\", \"Hora\").withColumnRenamed(\"_c6\", \"Minuto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1004895"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_agua_cabe.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como ya se analizó anteriormente en Spark Core la diferencia entre edificios y UPO en esta parte se decide no volver a analizar esa comparativa y analizar unicamente los edificios. Además se asume que los valores negativos en consumo con erróneos y por ello se eliminan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "d_agua_EDIF_sin_neg = [Edificio: string, Consumo: double ... 5 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[Edificio: string, Consumo: double ... 5 more fields]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val d_agua_EDIF_sin_neg = d_agua_cabe.filter($\"Consumo\" >= 0.0 && \"$Edificio\" != \"AGUA_UPO_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1004748"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_agua_EDIF_sin_neg.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+----+---+---+----+------+\n",
      "|   Edificio|Consumo| Año|Mes|Día|Hora|Minuto|\n",
      "+-----------+-------+----+---+---+----+------+\n",
      "|AGUA_EDIF_1|    0.0|2013|  1|  1|   0|     0|\n",
      "|AGUA_EDIF_1|    0.0|2013|  1|  1|   0|    15|\n",
      "|AGUA_EDIF_1|    0.0|2013|  1|  1|   0|    30|\n",
      "|AGUA_EDIF_1|    0.0|2013|  1|  1|   0|    45|\n",
      "|AGUA_EDIF_1|    0.0|2013|  1|  1|   1|     0|\n",
      "+-----------+-------+----+---+---+----+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "d_agua_EDIF_sin_neg.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Cálculo del consumo de agua mensual *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que en Spark Core se han calculado los consumos por edificios, en este caso se calculan los consumos en función de los meses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "agua_mes = [Mes: int, Consumo mensual: double]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[Mes: int, Consumo mensual: double]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val agua_mes = d_agua_EDIF_sin_neg.groupBy($\"Mes\")\n",
    "    .agg(sum($\"Consumo\").as(\"Consumo mensual\"))\n",
    "    .sort($\"Consumo mensual\".desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------+\n",
      "|Mes|   Consumo mensual|\n",
      "+---+------------------+\n",
      "| 10| 6553.194999999841|\n",
      "| 11| 6348.106999999831|\n",
      "|  6| 6243.957999999862|\n",
      "|  5| 6085.569999999883|\n",
      "|  9| 6005.066999999882|\n",
      "|  4| 5424.244999999892|\n",
      "| 12|5223.0379999999295|\n",
      "|  7|5222.9399999999005|\n",
      "|  1| 5100.248999999954|\n",
      "|  2|  4779.97699999989|\n",
      "|  3| 4550.615999999952|\n",
      "|  8|3631.9559999999583|\n",
      "+---+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "agua_mes.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa como los meses en los que más agua se consumo son octubre y noviembre y el mes que menos es Agosto, el último tiene una explicación bastante lógica y es que en el mes de Agosto la mayoría de la gente se encuentra de vacaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2.2\"></a>\n",
    "### * 2.2. Datos electricidad. *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "d_elec = [_c0: string, _c1: double ... 5 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[_c0: string, _c1: double ... 5 more fields]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val d_elec= spark.read.format(\"csv\").\n",
    "option(\"delimiter\", \";\").\n",
    "option(\"header\", false). // los datos no incorporan cabecera\n",
    "option(\"inferSchema\", true).\n",
    "load(\"hdfs:///eoi/Proyecto-Final/2013electricidad.csv\").cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- _c1: double (nullable = true)\n",
      " |-- _c2: integer (nullable = true)\n",
      " |-- _c3: integer (nullable = true)\n",
      " |-- _c4: integer (nullable = true)\n",
      " |-- _c5: integer (nullable = true)\n",
      " |-- _c6: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "d_elec.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "d_elec_cabe = [Edificio: string, Consumo: double ... 5 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[Edificio: string, Consumo: double ... 5 more fields]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val d_elec_cabe = d_elec.withColumnRenamed(\"_c0\", \"Edificio\").withColumnRenamed(\"_c1\", \"Consumo\").withColumnRenamed(\"_c2\", \"Año\").withColumnRenamed(\"_c3\", \"Mes\").withColumnRenamed(\"_c4\", \"Día\").withColumnRenamed(\"_c5\", \"Hora\").withColumnRenamed(\"_c6\", \"Minuto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "998289"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_elec_cabe.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como ya se analizó anteriormente en Spark Core la diferencia entre edificios y UPO en esta parte se decide no volver a analizar esa comparativa y analizar unicamente los edificios. Además se asume que los valores negativos en consumo con erróneos y por ello se eliminan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "d_ELEC_EDIF_sin_neg = [Edificio: string, Consumo: double ... 5 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[Edificio: string, Consumo: double ... 5 more fields]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val d_ELEC_EDIF_sin_neg = d_elec_cabe.filter($\"Consumo\" >= 0.0 && \"$Edificio\" != \"ELEC_UPO_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "996068"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_ELEC_EDIF_sin_neg.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+----+---+---+----+------+\n",
      "|   Edificio|Consumo| Año|Mes|Día|Hora|Minuto|\n",
      "+-----------+-------+----+---+---+----+------+\n",
      "|ELEC_EDIF_1|  1.354|2013|  1|  1|   0|     0|\n",
      "|ELEC_EDIF_1|  1.521|2013|  1|  1|   0|    15|\n",
      "|ELEC_EDIF_1|  1.239|2013|  1|  1|   0|    30|\n",
      "|ELEC_EDIF_1|  1.347|2013|  1|  1|   0|    45|\n",
      "|ELEC_EDIF_1|    1.3|2013|  1|  1|   1|     0|\n",
      "+-----------+-------+----+---+---+----+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "d_ELEC_EDIF_sin_neg.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Cálculo del consumo de electricidad mensual *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "elec_mes = [Mes: int, Consumo mensual: double]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[Mes: int, Consumo mensual: double]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val elec_mes = d_ELEC_EDIF_sin_neg.groupBy($\"Mes\")\n",
    "    .agg(sum($\"Consumo\").as(\"Consumo mensual\"))\n",
    "    .sort($\"Consumo mensual\".desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------+\n",
      "|Mes|   Consumo mensual|\n",
      "+---+------------------+\n",
      "|  9|2052214.4620000173|\n",
      "| 10|1880115.5610000044|\n",
      "| 12|1841825.4030000065|\n",
      "| 11|1764695.5759999983|\n",
      "|  7|1712505.8759999909|\n",
      "|  1|1529654.0739999951|\n",
      "|  6| 1512178.091000014|\n",
      "|  2|1422766.8090000013|\n",
      "|  3|1300775.5259999982|\n",
      "|  5|1289801.8820000004|\n",
      "|  4|1099519.8939999992|\n",
      "|  8| 935923.2849999974|\n",
      "+---+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "elec_mes.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa como los meses en los que más electricidad se consume son Septiembre, Octubre y Diciembre, esto es debido a que en estos meses existe menos luz natural y es necesario consumir una mayor cantidad de luz artificial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2.3\"></a>\n",
    "### * 2.2. Datos ficticios. *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "d_ficticios = [Edificio: string, Direccion: string ... 2 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[Edificio: string, Direccion: string ... 2 more fields]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val d_ficticios= spark.read.format(\"csv\").\n",
    "option(\"delimiter\", \";\").\n",
    "option(\"header\", true). \n",
    "option(\"inferSchema\", true).\n",
    "load(\"hdfs:///eoi/Proyecto-Final/Datos_ficticios.csv\").cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_ficticios.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---------------+---------+-----------+\n",
      "|       Edificio|      Direccion|Provincia|AforoMaximo|\n",
      "+---------------+---------------+---------+-----------+\n",
      "|         EDIF_1|Direccion upo-1|  Sevilla|      18802|\n",
      "|EDIF_1_CAFETERI|Direccion upo-1|  Sevilla|       3571|\n",
      "|        EDIF_10|Direccion upo-1|  Sevilla|      15912|\n",
      "|        EDIF_11|Direccion upo-1|  Sevilla|      15176|\n",
      "|        EDIF_12|Direccion upo-1|  Sevilla|      18747|\n",
      "|        EDIF_13|Direccion upo-1|  Sevilla|      14833|\n",
      "|        EDIF_14|Direccion upo-1|  Sevilla|      16843|\n",
      "|        EDIF_15|Direccion upo-1|  Sevilla|       6698|\n",
      "|        EDIF_16|Direccion upo-1|  Sevilla|      19598|\n",
      "|        EDIF_17|Direccion upo-1|  Sevilla|       6314|\n",
      "|EDIF_17_COMEDOR|Direccion upo-1|  Sevilla|      12827|\n",
      "| EDIF_18_KIOSCO|Direccion upo-1|  Sevilla|      12557|\n",
      "|         EDIF_2|Direccion upo-2|  Sevilla|       8878|\n",
      "|        EDIF_20|Direccion upo-2|  Sevilla|       8375|\n",
      "|        EDIF_21|Direccion upo-2|  Sevilla|      12074|\n",
      "|         EDIF_3|Direccion upo-3|  Sevilla|      13149|\n",
      "|        EDIF_31|Direccion upo-3|  Sevilla|      10095|\n",
      "|        EDIF_32|Direccion upo-3|  Sevilla|      14785|\n",
      "|        EDIF_36|Direccion upo-3|  Sevilla|      19549|\n",
      "|         EDIF_4|Direccion upo-4|  Sevilla|      15035|\n",
      "|        EDIF_42|Direccion upo-4|  Sevilla|       3154|\n",
      "|        EDIF_43|Direccion upo-4|  Sevilla|       7422|\n",
      "|        EDIF_44|Direccion upo-4|  Sevilla|      11883|\n",
      "|        EDIF_45|Direccion upo-4|  Sevilla|      10785|\n",
      "|         EDIF_5|Direccion upo-5|  Sevilla|      16427|\n",
      "|         EDIF_6|Direccion upo-6|  Sevilla|       6706|\n",
      "|         EDIF_7|Direccion upo-7|  Sevilla|      19653|\n",
      "|         EDIF_8|Direccion upo-8|  Sevilla|      16783|\n",
      "|            UPO|           null|  Sevilla|       null|\n",
      "+---------------+---------------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "d_ficticios.show(29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Edificio: string (nullable = true)\n",
      " |-- Direccion: string (nullable = true)\n",
      " |-- Provincia: string (nullable = true)\n",
      " |-- AforoMaximo: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "d_ficticios.printSchema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3\"></a>\n",
    "### * 3. Unión de los datasets y análisis. *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3.1\"></a>\n",
    "### * 3.1 Consumo agua en función de los edificios. *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se decide modificar un poco la estructura de los datasets y crear una columna de tipo Time Stamp que agrupe la fecha en una única variable, con el fin de que al análizar la unión sea más visual y además cambiar el nombre de Edificio ya que si no coincidía con el datos ficticios y no se podría llevar a cabo la union"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se crean los encabezamos del dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "db_agua_5 = [Edificio agua: string, Consumo m3: double ... 5 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[Edificio agua: string, Consumo m3: double ... 5 more fields]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val db_agua_5 = d_agua.toDF(\"Edificio agua\", \"Consumo m3\", \"Año\", \"Mes\", \"Día\", \"Hora\",\"Minutos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "db_agua_4 = [Edificio agua: string, Consumo m3: double ... 1 more field]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[Edificio agua: string, Consumo m3: double ... 1 more field]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val db_agua_4 = db_agua_5.select($\"Edificio agua\",$\"Consumo m3\".cast(\"Double\"),(concat($\"Año\", lit(\"-\"), \n",
    "                                          $\"Mes\", lit(\"-\"), \n",
    "                                          $\"Día\", lit(\" \"), \n",
    "                                          $\"Hora\", lit(\":\"),\n",
    "                                          $\"MinutoS\").cast(\"Timestamp\").as(\"Fecha\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para poder unirlos se realiza el mismo paso que en Core quitandole AGUA_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "db_agua_3 = [Edificio agua: string, Consumo m3: double ... 1 more field]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[Edificio agua: string, Consumo m3: double ... 1 more field]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val db_agua_3 = db_agua_4.withColumn(\"Edificio agua\", regexp_replace(db_agua_4(\"Edificio agua\"),\"AGUA_\", \"\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "db_agua_2 = [Edificio agua: string, Consumo m3: double ... 1 more field]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[Edificio agua: string, Consumo m3: double ... 1 more field]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val db_agua_2 = db_agua_3.filter($\"Consumo m3\" >= 0.0 && \"$Edificio agua\" != \"AGUA_UPO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "db_agua_edificio = [Edificio agua: string, Consumo mensual m3: double]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[Edificio agua: string, Consumo mensual m3: double]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val db_agua_edificio = db_agua_2.groupBy($\"Edificio agua\")\n",
    "    .agg(sum($\"Consumo m3\").as(\"Consumo mensual m3\"))\n",
    "    .sort($\"Consumo mensual m3\".desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3.2\"></a>\n",
    "### * 3.1 Consumo electricidad en función de los edificios. *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "db_elec_4 = [Edificio elec: string, Consumo kW/h: double ... 5 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[Edificio elec: string, Consumo kW/h: double ... 5 more fields]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val db_elec_4 = d_elec.toDF(\"Edificio elec\", \"Consumo kW/h\", \"Año\", \"Mes\", \"Día\", \"Hora\",\"Minutos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "db_elec_3 = [Edificio elec: string, Consumo kW/h: double ... 1 more field]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[Edificio elec: string, Consumo kW/h: double ... 1 more field]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val db_elec_3 = db_elec_4.select($\"Edificio elec\",$\"Consumo kW/h\".cast(\"Double\"),(concat($\"Año\", lit(\"-\"), \n",
    "                                          $\"Mes\", lit(\"-\"), \n",
    "                                          $\"Día\", lit(\" \"), \n",
    "                                          $\"Hora\", lit(\":\"),\n",
    "                                          $\"MinutoS\").cast(\"Timestamp\").as(\"Fecha\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "db_elec_2 = [Edificio elec: string, Consumo kW/h: double ... 1 more field]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[Edificio elec: string, Consumo kW/h: double ... 1 more field]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val db_elec_2 = db_elec_3.filter($\"Consumo kW/h\" >= 0.0 && \"$Edificio elec\" != \"ELEC_UPO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "db_elec = [Edificio elec: string, Consumo kW/h: double ... 1 more field]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[Edificio elec: string, Consumo kW/h: double ... 1 more field]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val db_elec = db_elec_2.withColumn(\"Edificio elec\", regexp_replace(db_elec_2(\"Edificio elec\"),\"ELEC_\", \"\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "db_elec_edificio = [Edificio elec: string, Consumo mensual kW/h: double]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[Edificio elec: string, Consumo mensual kW/h: double]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val db_elec_edificio = db_elec.groupBy($\"Edificio elec\")\n",
    "    .agg(sum($\"Consumo kW/h\").as(\"Consumo mensual kW/h\"))\n",
    "    .sort($\"Consumo mensual kW/h\".desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "join_1 = [Edificio elec: string, Consumo mensual kW/h: double ... 2 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[Edificio elec: string, Consumo mensual kW/h: double ... 2 more fields]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val join_1 = db_elec_edificio.join(db_agua_edificio, db_elec_edificio.col(\"Edificio elec\") === db_agua_edificio.col(\"Edificio agua\"), \"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------------+---------------+------------------+\n",
      "|  Edificio elec|Consumo mensual kW/h|  Edificio agua|Consumo mensual m3|\n",
      "+---------------+--------------------+---------------+------------------+\n",
      "|         EDIF_3|  173988.71000000104|         EDIF_3| 952.7199999998963|\n",
      "|         EDIF_8|  53756.026000000435|         EDIF_8| 348.9499999999778|\n",
      "|        EDIF_42|   6325.060999998495|        EDIF_42| 6.159999999999969|\n",
      "|        EDIF_16|  23105.522000000114|        EDIF_16| 4197.345999999584|\n",
      "|EDIF_1_CAFETERI|  123496.35400000021|EDIF_1_CAFETERI| 709.8699999999565|\n",
      "|        EDIF_10|  224691.37899999702|        EDIF_10| 628.2499999999555|\n",
      "|        EDIF_12|   82013.96899999968|        EDIF_12| 396.7199999999699|\n",
      "|        EDIF_13|  27464.337000000156|        EDIF_13|126.06000000000698|\n",
      "|         EDIF_6|   135662.6199999995|         EDIF_6| 479.7899999999386|\n",
      "|        EDIF_14|  252734.93899999987|        EDIF_14| 301.3999999999884|\n",
      "|        EDIF_21|   579830.6299999943|        EDIF_21|387.07199999997704|\n",
      "|        EDIF_45|  285486.19299999875|        EDIF_45|               0.0|\n",
      "|        EDIF_31|   57470.26199999967|        EDIF_31|  90.3800000000023|\n",
      "|        EDIF_43|   7829.521000000247|        EDIF_43| 337.2700000000003|\n",
      "|         EDIF_5|   41959.54400000004|         EDIF_5|279.11999999999387|\n",
      "|        EDIF_44|  105796.46400000039|        EDIF_44|163.32000000000352|\n",
      "|         EDIF_2|    218905.908000002|         EDIF_2| 369.8799999999802|\n",
      "|        EDIF_17|  219905.69300000125|        EDIF_17| 1219.489999999943|\n",
      "|         EDIF_4|   35481.16900000012|         EDIF_4| 472.3299999999401|\n",
      "|        EDIF_32|   160687.1759999992|        EDIF_32| 401.4299999999219|\n",
      "|        EDIF_36|   9568.368000000246|        EDIF_36| 925.7999999998241|\n",
      "|EDIF_17_COMEDOR|   79210.64399999994|EDIF_17_COMEDOR| 344.9100000000053|\n",
      "|        EDIF_11|  195154.23400000078|        EDIF_11| 527.4899999999636|\n",
      "| EDIF_18_KIOSCO|  30028.250999999847| EDIF_18_KIOSCO|182.85000000000463|\n",
      "|        EDIF_20|  1625734.7639999923|        EDIF_20| 6367.870000000127|\n",
      "|        EDIF_15|   263737.3690000025|        EDIF_15|3045.9600000001237|\n",
      "|         EDIF_7|  266688.74300000194|         EDIF_7|1807.7299999997442|\n",
      "|            UPO|1.2911443386999983E7|            UPO|39388.879999999896|\n",
      "|         EDIF_1|  143819.20200000048|         EDIF_1| 709.8699999999565|\n",
      "+---------------+--------------------+---------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "join_1.show(29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "join_2 = [Edificio elec: string, Consumo mensual kW/h: double ... 6 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[Edificio elec: string, Consumo mensual kW/h: double ... 6 more fields]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val join_2 = join_1.join(d_ficticios, join_1.col(\"Edificio agua\") === d_ficticios.col(\"Edificio\"), \"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "total_1 = [Edificio: string, Consumo mensual kW/h: double ... 2 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[Edificio: string, Consumo mensual kW/h: double ... 2 more fields]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val total_1 = join_2.select( \"Edificio\", \"Consumo mensual kW/h\", \"Consumo mensual m3\", \"AforoMaximo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "total_final = [Edificio: string, Consumo mensual kW/h: double ... 2 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[Edificio: string, Consumo mensual kW/h: double ... 2 more fields]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val total_final = total_1.sort($\"AforoMaximo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------------+------------------+-----------+\n",
      "|       Edificio|Consumo mensual kW/h|Consumo mensual m3|AforoMaximo|\n",
      "+---------------+--------------------+------------------+-----------+\n",
      "|            UPO|1.2911443386999983E7|39388.879999999896|       null|\n",
      "|        EDIF_42|   6325.060999998495| 6.159999999999969|       3154|\n",
      "|EDIF_1_CAFETERI|  123496.35400000021| 709.8699999999565|       3571|\n",
      "|        EDIF_17|  219905.69300000125| 1219.489999999943|       6314|\n",
      "|        EDIF_15|   263737.3690000025|3045.9600000001237|       6698|\n",
      "|         EDIF_6|   135662.6199999995| 479.7899999999386|       6706|\n",
      "|        EDIF_43|   7829.521000000247| 337.2700000000003|       7422|\n",
      "|        EDIF_20|  1625734.7639999923| 6367.870000000127|       8375|\n",
      "|         EDIF_2|    218905.908000002| 369.8799999999802|       8878|\n",
      "|        EDIF_31|   57470.26199999967|  90.3800000000023|      10095|\n",
      "|        EDIF_45|  285486.19299999875|               0.0|      10785|\n",
      "|        EDIF_44|  105796.46400000039|163.32000000000352|      11883|\n",
      "|        EDIF_21|   579830.6299999943|387.07199999997704|      12074|\n",
      "| EDIF_18_KIOSCO|  30028.250999999847|182.85000000000463|      12557|\n",
      "|EDIF_17_COMEDOR|   79210.64399999994| 344.9100000000053|      12827|\n",
      "|         EDIF_3|  173988.71000000104| 952.7199999998963|      13149|\n",
      "|        EDIF_32|   160687.1759999992| 401.4299999999219|      14785|\n",
      "|        EDIF_13|  27464.337000000156|126.06000000000698|      14833|\n",
      "|         EDIF_4|   35481.16900000012| 472.3299999999401|      15035|\n",
      "|        EDIF_11|  195154.23400000078| 527.4899999999636|      15176|\n",
      "|        EDIF_10|  224691.37899999702| 628.2499999999555|      15912|\n",
      "|         EDIF_5|   41959.54400000004|279.11999999999387|      16427|\n",
      "|         EDIF_8|  53756.026000000435| 348.9499999999778|      16783|\n",
      "|        EDIF_14|  252734.93899999987| 301.3999999999884|      16843|\n",
      "|        EDIF_12|   82013.96899999968| 396.7199999999699|      18747|\n",
      "|         EDIF_1|  143819.20200000048| 709.8699999999565|      18802|\n",
      "|        EDIF_36|   9568.368000000246| 925.7999999998241|      19549|\n",
      "|        EDIF_16|  23105.522000000114| 4197.345999999584|      19598|\n",
      "|         EDIF_7|  266688.74300000194|1807.7299999997442|      19653|\n",
      "+---------------+--------------------+------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "total_final.show(29)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta tabla se pueden analizar los consumos totales en función de los edificios y ver que aforo máximo poseen los mismos.\n",
    "\n",
    "Se aprecia como no existe una relación directa entre consumos y aforo máximo. El edificio 45 es llamativo de nuevo, ya que no posee consumo de agua pero es uno de los que posee mayor consumo de electricidad y se podría afirmar que su aforo es medio. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo de guardado de datos "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se realiza un unico guardado  a modo de ejemplo, ya que el objetivo de este proyecto no es guardar todas las tablas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: org.apache.spark.sql.AnalysisException\n",
       "Message: org.apache.hadoop.hive.metastore.api.AlreadyExistsException: Database proyectofinal already exists;\n",
       "StackTrace:   at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:106)\n",
       "  at org.apache.spark.sql.hive.HiveExternalCatalog.doCreateDatabase(HiveExternalCatalog.scala:163)\n",
       "  at org.apache.spark.sql.catalyst.catalog.ExternalCatalog.createDatabase(ExternalCatalog.scala:69)\n",
       "  at org.apache.spark.sql.catalyst.catalog.SessionCatalog.createDatabase(SessionCatalog.scala:207)\n",
       "  at org.apache.spark.sql.execution.command.CreateDatabaseCommand.run(ddl.scala:70)\n",
       "  at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:70)\n",
       "  at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:68)\n",
       "  at org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:79)\n",
       "  at org.apache.spark.sql.Dataset$$anonfun$6.apply(Dataset.scala:190)\n",
       "  at org.apache.spark.sql.Dataset$$anonfun$6.apply(Dataset.scala:190)\n",
       "  at org.apache.spark.sql.Dataset$$anonfun$52.apply(Dataset.scala:3259)\n",
       "  at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:77)\n",
       "  at org.apache.spark.sql.Dataset.withAction(Dataset.scala:3258)\n",
       "  at org.apache.spark.sql.Dataset.<init>(Dataset.scala:190)\n",
       "  at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:75)\n",
       "  at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:642)\n",
       "  ... 48 elided\n",
       "Caused by: org.apache.hadoop.hive.metastore.api.AlreadyExistsException: Database proyectofinal already exists\n",
       "  at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_database(HiveMetaStore.java:891)\n",
       "  at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
       "  at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
       "  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
       "  at java.lang.reflect.Method.invoke(Method.java:498)\n",
       "  at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
       "  at com.sun.proxy.$Proxy29.create_database(Unknown Source)\n",
       "  at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createDatabase(HiveMetaStoreClient.java:644)\n",
       "  at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
       "  at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
       "  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
       "  at java.lang.reflect.Method.invoke(Method.java:498)\n",
       "  at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.invoke(RetryingMetaStoreClient.java:156)\n",
       "  at com.sun.proxy.$Proxy30.createDatabase(Unknown Source)\n",
       "  at org.apache.hadoop.hive.ql.metadata.Hive.createDatabase(Hive.java:306)\n",
       "  at org.apache.spark.sql.hive.client.HiveClientImpl$$anonfun$createDatabase$1.apply$mcV$sp(HiveClientImpl.scala:303)\n",
       "  at org.apache.spark.sql.hive.client.HiveClientImpl$$anonfun$createDatabase$1.apply(HiveClientImpl.scala:303)\n",
       "  at org.apache.spark.sql.hive.client.HiveClientImpl$$anonfun$createDatabase$1.apply(HiveClientImpl.scala:303)\n",
       "  at org.apache.spark.sql.hive.client.HiveClientImpl$$anonfun$withHiveState$1.apply(HiveClientImpl.scala:272)\n",
       "  at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:210)\n",
       "  at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:209)\n",
       "  at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:255)\n",
       "  at org.apache.spark.sql.hive.client.HiveClientImpl.createDatabase(HiveClientImpl.scala:302)\n",
       "  at org.apache.spark.sql.hive.HiveExternalCatalog$$anonfun$doCreateDatabase$1.apply$mcV$sp(HiveExternalCatalog.scala:164)\n",
       "  at org.apache.spark.sql.hive.HiveExternalCatalog$$anonfun$doCreateDatabase$1.apply(HiveExternalCatalog.scala:164)\n",
       "  at org.apache.spark.sql.hive.HiveExternalCatalog$$anonfun$doCreateDatabase$1.apply(HiveExternalCatalog.scala:164)\n",
       "  at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:97)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"create database ProyectoFinal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lastException = null\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Name: org.apache.spark.sql.AnalysisException\n",
       "Message: Table `ProyectoFinal`.`datos` already exists.;\n",
       "StackTrace:   at org.apache.spark.sql.DataFrameWriter.saveAsTable(DataFrameWriter.scala:393)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_ficticios.write.saveAsTable(\"ProyectoFinal.datos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------+-----------+---------+-----------+\n",
      "| name|     database|description|tableType|isTemporary|\n",
      "+-----+-------------+-----------+---------+-----------+\n",
      "|datos|proyectofinal|       null|  MANAGED|      false|\n",
      "+-----+-------------+-----------+---------+-----------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "lastException: Throwable = null\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark.catalog.listTables().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.catalog.setCurrentDatabase(\"ProyectoFinal\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark - Scala",
   "language": "scala",
   "name": "spark_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
